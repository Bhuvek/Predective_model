{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17253460",
   "metadata": {},
   "source": [
    "# DESCRIPTION ABOUT MODEL:\n",
    "1. This model work well with Binary Classification Model\n",
    "\n",
    "2. You just have to import the model and add model name to Models{}\n",
    "\n",
    "3. We also find the best params using the Hyper Parameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd9e02",
   "metadata": {},
   "source": [
    "# IMPORT ALL NECESSARY LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d36135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay,precision_score,recall_score\\\n",
    "                            ,f1_score,roc_auc_score,roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f8331",
   "metadata": {},
   "source": [
    "1. Here we use the LogisticRegression , DecisionTreeClassifier,RandomForestClassifier model for this classification problem\n",
    "2. Then we train our model using FOR loop which iterate through every model\n",
    "3. Then we predict our model\n",
    "4. Now we check the performance for Training dataset using:\n",
    "A.  Accuracy Score\n",
    "B.  F1 Score \n",
    "C.  Precision Score \n",
    "D.  Recall Score\n",
    "E.  ROC AUR Score\n",
    "5. Now we check the performance for Testing dataset using:\n",
    "A.  Accuracy Score\n",
    "B.  F1 Score \n",
    "C.  Precision Score \n",
    "D.  Recall Score\n",
    "E.  ROC AUR Score\n",
    "6. Then we print our train and test performance\n",
    "7. Now we can use the best model on dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eccdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    \"Logisitic Regression\":LogisticRegression(),\n",
    "    \"Decision Tree\":DecisionTreeClassifier(),\n",
    "    \"Random Forest\":RandomForestClassifier()\n",
    "}\n",
    "for i in range(len(list(models))):\n",
    "    model=list(models.values())[i] \n",
    "    model.fit(X_train,y_train) \n",
    "    \n",
    "    # PREDICTIONS\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Training set performance \n",
    "    model_train_accuracy = accuracy_score(y_train,y_train_pred)\n",
    "    model_train_f1 = f1_score(y_train, y_train_pred ,average='weighted')\n",
    "    model_train_precision = precision_score(y_train,y_train_pred)\n",
    "    model_train_recall = recall_score(y_train, y_train_pred)\n",
    "    model_train_rocauc_score = roc_auc_score(y_train,y_train_pred)\n",
    "    \n",
    "    # Test set performance\n",
    "    model_test_accuracy = accuracy_score(y_test , y_test_pred)\n",
    "    model_test_f1 = f1_score(y_test , y_test_pred ,average='weighted')\n",
    "    model_test_precision = precision_score(y_test ,y_test_pred)\n",
    "    model_test_recall = recall_score(y_test, y_test_pred)\n",
    "    model_test_rocauc_score = roc_auc_score(y_test,y_test_pred)\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training dataset')\n",
    "    print(f'- Accuracy : {model_train_accuracy}')\n",
    "    print(f'- F1 Score : {model_train_f1}')\n",
    "    print(f'- Precision : {model_train_precision}')\n",
    "    print(f'- Recall : {model_train_recall}')\n",
    "    print(f'- Roc_Auc_Score: {model_train_rocauc_score}')\n",
    "    \n",
    "    print('-----------------------------------------------------')\n",
    "    \n",
    "    print('Model performance for Testing dataset')\n",
    "    print(f'- Accuracy : {model_test_accuracy}')\n",
    "    print(f'- F1 Score : {model_test_f1}')\n",
    "    print(f'- Precision : {model_test_precision}')\n",
    "    print(f'- Recall : {model_test_recall}')\n",
    "    print(f'- Roc_Auc_Score: {model_test_rocauc_score}')\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec09ec0",
   "metadata": {},
   "source": [
    "# HYPER PARAMETER TUNNING "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc204a6",
   "metadata": {},
   "source": [
    "Now we define the hyper parameter accoring to model (Here we uses RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9011ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\"max_depth\" :[5,8,15,None,10,12,13],\n",
    "            \"max_features\" : [5,6,9,7,\"auto\",8],\n",
    "            \"min_samples_split\" : [2,8,15,20,22,18],\n",
    "            \"n_estimators\" : [100,200,150,180,500,1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f75678",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomcv_models = [('RF', RandomForestClassifier(), rf_params)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model_param ={}\n",
    "for name,model,params in randomcv_models:\n",
    "    random=RandomizedSearchCV(estimator=model,\n",
    "                             param_distributions=params,\n",
    "                             n_iter=100,\n",
    "                             cv=3,\n",
    "                             verbose=2,\n",
    "                             n_jobs=-1)\n",
    "    \n",
    "    random.fit(X_train,y_train)\n",
    "    model_param[name] = random.best_params_\n",
    "    \n",
    "for model_name in model_param:\n",
    "    print(f\"Best Param for {model_name} : \")\n",
    "    print(model_param[model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f3076a",
   "metadata": {},
   "source": [
    "Here we got the best params for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9048b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=200,min_samples_split=18,max_features=7, max_depth=10)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e55bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc2c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
